# ğŸ™ï¸ AI Meeting Tracker

**Self-hosted AI-powered meeting transcription and task extraction**

## âœ¨ Features

- ğŸ¯ **Upload recordings** (MP3, MP4, WAV, M4A) - up to 1.5 hours
- ğŸ™ï¸ **Transcribe with Whisper** (local, no API costs)
- ğŸ¤– **Extract tasks with Ollama** (Llama 3.1 or Mistral)
- ğŸ’¬ **Chat about meetings** - ask questions about transcript
- ğŸ“š **Meeting history** - last 10 meetings in sidebar
- ğŸ’¾ **Database persistence** - SQLite storage for all meetings
- âœ… **Structured tasks** with owner, deadline, confidence scores
- ğŸ”’ **100% self-hosted** - no cloud dependencies, privacy-first

## ğŸ› ï¸ Tech Stack

- **Backend:** Python 3.11+ with FastAPI  
- **Database:** SQLite with SQLAlchemy ORM
- **Transcription:** OpenAI Whisper (100% local, no API)
- **AI Extraction:** Ollama (Llama 3.1 8B)
- **Frontend:** Vue 3 + Vite + Vue Router
- **Styling:** Custom CSS with glassmorphism design

## ğŸ“‹ System Requirements

- **Python:** 3.11 or higher
- **Node.js:** 18+ 
- **RAM:** 10GB+ (for Whisper + Ollama)
- **Disk:** ~5GB for AI models
- **GPU:** Optional (CPU works fine, just slower)
- **OS:** Linux, macOS, Windows (WSL)
- **FFmpeg:** Required for audio processing

## ğŸš€ Quick Start

### 0. Install FFmpeg (Required)

```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg

# macOS
brew install ffmpeg

# Check installation
ffmpeg -version
```

### 1. Install Ollama

```bash
chmod +x scripts/install_ollama.sh
./scripts/install_ollama.sh
```

This will:
- Install Ollama
- Pull Llama 3.1 8B model (~4.7GB)

### 2. Setup Backend

```bash
chmod +x setup_backend.sh
./setup_backend.sh
```

### 3. Setup Frontend

```bash
chmod +x setup_frontend.sh
./setup_frontend.sh
```

### 4. Run the Application

**Terminal 1** - Start Backend:
```bash
cd backend
source venv/bin/activate
python main.py
```

Backend runs on: `http://localhost:8000`

**Terminal 2** - Start Frontend:
```bash
cd frontend
npm run dev
```

Frontend runs on: `http://localhost:5173`

### 5. Test It

1. Open `http://localhost:5173` in your browser
2. Upload a meeting recording
3. Click "Process Recording"
4. Wait for transcription + AI extraction (~1-2 minutes)
5. View extracted tasks with confidence scores!

## ğŸ“– How It Works

1. **Upload** â†’ File saved to `backend/uploads/`
2. **Transcribe** â†’ OpenAI Whisper converts full audio to text (up to 1.5 hours)
3. **Extract** â†’ Ollama (Llama 3.1) identifies action items from transcript
4. **Store** â†’ Meeting, tasks, and metadata saved to SQLite database
5. **Display** â†’ Tasks shown with owner, deadline, and confidence scores
6. **Chat** â†’ Ask questions about the meeting using AI

## ğŸ“ Project Structure

```
ProjectX/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”œâ”€â”€ database.py                # SQLAlchemy models
â”‚   â”œâ”€â”€ config.py                  # Environment configuration
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ transcription.py      # Whisper integration
â”‚   â”‚   â””â”€â”€ task_extractor.py     # Ollama task extraction
â”‚   â”œâ”€â”€ uploads/                   # Temporary file storage
â”‚   â””â”€â”€ meetings.db                # SQLite database
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.vue               # Main layout with history sidebar
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadPage.vue    # File upload interface
â”‚   â”‚   â”‚   â””â”€â”€ ResultsPage.vue   # Results with chat
â”‚   â”‚   â”œâ”€â”€ composables/
â”‚   â”‚   â”‚   â”œâ”€â”€ useHistory.js     # LocalStorage history
â”‚   â”‚   â”‚   â””â”€â”€ useSession.js     # Session management  
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”‚   â””â”€â”€ index.js          # Vue Router config
â”‚   â”‚   â”œâ”€â”€ style.css             # Modern dark theme
â”‚   â”‚   â””â”€â”€ main.js               # Vue entry point
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ install_ollama.sh         # Ollama installation
â”œâ”€â”€ .env.example                   # Environment config template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE                        # MIT License
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Change AI Model

Edit `backend/modules/task_extractor.py`:

```python
async def extract_tasks(transcript: str, model: str = "mistral:7b"):
    # Change model here
```

Available models:
- `llama3.1:8b` (default, best accuracy)
- `mistral:7b` (faster, good accuracy)
- `llama2:7b` (lighter)

Pull new models: `ollama pull mistral:7b`

### Change Whisper Model

Edit `backend/modules/transcription.py`:

```python
_model = WhisperModel("medium", device="cpu", compute_type="int8")
```

Models: `tiny`, `base`, `small`, `medium`, `large`

## ğŸ› Troubleshooting

**Ollama connection error:**
```bash
# Check if Ollama is running
ollama list

# Start Ollama service
ollama serve
```

**Whisper model download:**
- First run will download Whisper model (~150MB for base)
- This only happens once

**Port already in use:**
```bash
# Change port in backend/main.py
uvicorn.run(app, host="0.0.0.0", port=8001)
```

## ğŸ¯ Roadmap

**Current Status: Working Prototype with Database âœ…**

Completed:
- âœ… SQLite database persistence
- âœ… Meeting history and retrieval
- âœ… Chat feature for Q&A about meetings
- âœ… Full audio transcription (up to 1.5 hours)
- âœ… Vue Router with separate pages
- âœ… Modern UI with glassmorphism
- âœ… Health check API endpoint

Coming Soon (Production Ready):
- ğŸš§ Docker containerization
- ğŸš§ Production frontend build
- ğŸš§ Security hardening (rate limiting, file validation)
- ğŸš§ Deployment documentation

Future MVP Features:
- ğŸ“‹ Task editing (CRUD operations)
- ğŸ‘¥ Speaker diarization (identify who said what)
- ğŸ“Š Kanban board integration
- ğŸ¨ Enhanced UI animations
- ğŸ§ª Automated tests

## ğŸ“ License

MIT
##
Built with:
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) - Optimized Whisper
- [Ollama](https://ollama.com/) - Local LLM runtime
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python API
- [Vue 3](https://vuejs.org/) - Progressive framework

---

**Made with â¤ï¸ for productivity nerds who hate cloud subscriptions**
